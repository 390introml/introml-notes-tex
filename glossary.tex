\newglossaryentry{ML}{name={machine learning},description={using algorithms and models to analyze and draw inferences from patterns in data}}

\newglossaryentry{IID}{name={independent and identically distributed},description={within a set of observed events, each event is drawn from the same probability distribution and are all mutually independent}}

\newglossaryentry{induction}{name={induction},description={(from data)the assumption that testing data will be drawn from the same distribution as the training data}}

\newglossaryentry{estimation}{name={estimation},description={predicting a quantity from (perhaps noisy) measurements of it}}

\newglossaryentry{generalization}{name={generalization},description={in ML, the ability of a model to handle new, unseen data}}

\newglossaryentry{pclass}{name={problem class},description={the nature of the training data and the type of queries that will be made at testing time}}

\newglossaryentry{evalcriteria}{name={evaluation criteria},description={the metric which evaluate how well a model is able to perform, e.g., on new data}}

\newglossaryentry{algorithm}{name={algorithm},description={a computational process that describes how to produce an output from a set of inputs, e.g., an algorithm to train a machine learning model from training data}}

\newglossaryentry{supervised}{name={supervised learning},description={a learning system where the training data includes feature-label pairs}}

\newglossaryentry{unsupervised}{name={unsupervised learning},description={a learning system where the training data does not include labels, i.e. the goal is to find some pattern or structure inherent to the data}}

\newglossaryentry{regression}{name={regression},description={in ML, given a new input vector, predict the value of the output label}}

\newglossaryentry{linreg}{name={linear regression},description={regression, where a linear relationship is assumed between a feature vector and a scalar output}}

\newglossaryentry{classification}{name={classification},description={given a new input vector, predict the class that it belongs to}}

\newglossaryentry{clustering}{name={clustering},description={given a set of samples, find a partitioning of the data that groups similar samples together}}

\newglossaryentry{dimensionality reduction}{name={dimensionality reduction},description={re-represent a set of data points in a lower dimensional space}}

\newglossaryentry{RL}{name={reinforcement learning},description={determing how an agent should make (a series of) action(s) when interacting with an environment in order to maximize a notion of reward}}

\newglossaryentry{loss}{name={loss function},description={how much penalty will be incurred when a particular guess is made, in comparison to what the true answer is}}

\newglossaryentry{training loss}{name={training loss},description={the performance of the model during training on accurately making decisions from training data}}

\newglossaryentry{testing loss}{name={testing loss},description={the performance of the model during testing on accurately making decisions from testing data}}

\newglossaryentry{regularization}{name={regularization},description={in ML, the enforcement of knowledge known \textit{a priori} about unknown variables when crafting and minimizing an objective function during model training}}

\newglossaryentry{overfit}{name={overfit},description={when a model is too specific to the training data during the training stage and (typically) does not perform well on previously unseen data during testing}}

\newglossaryentry{strucerror}{name={structural error},description={error that arises when there does exist a hypothesis within the hypothesis class that is able to perform well on the data}}

\newglossaryentry{esterror}{name={estimation error},description={error that arises because we do not have enough data (or the data are in some way unhelpful) to allow us to choose a good hypothesis or because we didn't solve the optimization problem well enough to find the best hypothesis given the data that we had.}}

\newglossaryentry{learning algo}{name={learning algorithm},description={the procedure that takes a data set as input and returns a hypothesis}}

\newglossaryentry{hyperparam}{name={hyperparameters},description={parameters which are specific to the learning algorithm, not the parameters of a ML model}}

\newglossaryentry{gd}{name={gradient descent},description={an iterative, optimization algorithm for finding a local minimum of a function}}

\newglossaryentry{convex}{name={convex (function)},description={real-valued function is called convex if the line segment between any two points on the graph of the function lies above the graph between the two points}}

\newglossaryentry{stochastic}{name={stochastic},description={probabilistic, or, random}}

\newglossaryentry{sgd}{name={stochastic gradient descent},description={in the case where the objective function is a finite sum, a variant of gradient descent where the descent direction is estimated using one item--selected at random--in the finite sum}}

\newglossaryentry{neuron}{name={neuron},description={nodes or units through which data flows. neurons are the base units of neural networks}}

\newglossaryentry{nn}{name={neural network},description={a collection of neurons which process a set of input features and produces an output label}}

\newglossaryentry{nonparameteric}{name={non-parametric method},description={in ML, a class of methods that does not have a fixed parameterization in advance}}

\newglossaryentry{tree}{name={(decision) tree},description={in ML, a network-based, supervised learning model where the goal is to produce a label based on the input features based on whether the feature satisfies a series of conditions (or not)}}

\newglossaryentry{batch}{name={batch},description={in the context of gradient descent, the approach of using all of the data points when, e.g., computing the gradient direction}}

\newglossaryentry{mb}{name={mini-batch},description={in the context of gradient descent, the approach of considering a subset of the measurements to estimate, e.g., the gradient direction}}
